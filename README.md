# ğŸ“ˆ Real-time Stock Market Data Pipeline

> **End-to-end streaming analytics platform with Kafka, Airflow, DBT, Snowflake, and Power BI**

[![Apache Kafka](https://img.shields.io/badge/Kafka-Event%20Streaming-231F20?style=flat-square&logo=apache-kafka)](https://kafka.apache.org/)
[![Apache Airflow](https://img.shields.io/badge/Airflow-Orchestration-017CEE?style=flat-square&logo=apache-airflow)](https://airflow.apache.org/)
[![DBT](https://img.shields.io/badge/DBT-Data%20Transformation-FF694B?style=flat-square&logo=dbt)](https://www.getdbt.com/)
[![Snowflake](https://img.shields.io/badge/Snowflake-Data%20Warehouse-29B5E8?style=flat-square&logo=snowflake)](https://www.snowflake.com/)
[![MinIO](https://img.shields.io/badge/MinIO-Object%20Storage-C72E49?style=flat-square&logo=minio)](https://min.io/)

## ğŸ¯ Overview

A **production-grade real-time data pipeline** ingesting live stock market data from Finnhub API, processing through **Medallion Architecture (Bronze â†’ Silver â†’ Gold)** using DBT, and delivering actionable insights via Power BI dashboards. Built with modern data stack for scalability and reliability.

### âœ¨ Key Features

- **âš¡ Real-time Streaming** - Kafka for low-latency data ingestion (5 major stocks: AAPL, MSFT, TSLA, GOOGL, AMZN)
- **ğŸ—„ï¸ Object Storage** - MinIO (S3-compatible) for data lake persistence
- **ğŸ”„ Orchestration** - Apache Airflow for automated data pipeline scheduling
- **ğŸ—ï¸ Medallion Architecture** - Bronze (raw) â†’ Silver (cleansed) â†’ Gold (business-ready)
- **ğŸ› ï¸ DBT Transformations** - SQL-based data modeling with version control
- **â˜ï¸ Snowflake Warehouse** - Scalable cloud data warehouse with compute separation
- **ğŸ“Š Power BI Integration** - DirectQuery for live dashboards (KPIs, candlestick charts, volatility analysis)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   DATA SOURCE LAYER                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“¡ Finnhub Stock API                                        â”‚
â”‚  â€¢ 60 API calls/minute                                       â”‚
â”‚  â€¢ Real-time market quotes                                   â”‚
â”‚  â€¢ Stocks: AAPL, MSFT, TSLA, GOOGL, AMZN                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
                  ğŸ Python Producer Script
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   STREAMING LAYER                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  âš¡ Apache Kafka + Zookeeper                                 â”‚
â”‚  â€¢ Topic: stock-quotes                                       â”‚
â”‚  â€¢ Producer: Fetch & publish every 6 seconds                 â”‚
â”‚  â€¢ Consumer: Stream to MinIO storage                         â”‚
â”‚  ğŸ–¥ï¸ Kafdrop UI - Monitoring & topic visualization          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
                  ğŸ Python Consumer Script
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   STORAGE LAYER (DATA LAKE)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ’¾ MinIO (S3-Compatible Object Storage)                    â”‚
â”‚  â€¢ Bucket: bronze-transactions                               â”‚
â”‚  â€¢ Format: JSON (partitioned by symbol & timestamp)         â”‚
â”‚  â€¢ Path: {symbol}/{timestamp}.json                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ORCHESTRATION LAYER                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ”„ Apache Airflow                                           â”‚
â”‚  â€¢ DAG: minio_to_snowflake                                   â”‚
â”‚  â€¢ Schedule: Every 1 minute (*/1 * * * *)                    â”‚
â”‚  â€¢ Tasks:                                                    â”‚
â”‚    1. Download files from MinIO bucket                       â”‚
â”‚    2. Stage files in Snowflake internal stage                â”‚
â”‚    3. COPY INTO bronze_stock_raw table                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   DATA WAREHOUSE (SNOWFLAKE)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â„ï¸ Bronze Layer (STOCKS_DB.BRONZE)                         â”‚
â”‚  â€¢ Table: bronze_stock_raw (VARIANT type for JSON)          â”‚
â”‚  â€¢ Raw data ingestion from MinIO                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
                    ğŸ› ï¸ DBT Transformations
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   DBT TRANSFORMATION LAYER                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ¥‰ BRONZE              â”‚  â€¢ Parse JSON to structured columnsâ”‚
â”‚                         â”‚  â€¢ Extract: price, high, low, etc  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ¥ˆ SILVER              â”‚  â€¢ Cleanse & validate data         â”‚
â”‚                         â”‚  â€¢ Round decimals, filter nulls    â”‚
â”‚                         â”‚  â€¢ curated_stocks model            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ¥‡ GOLD                â”‚  â€¢ Business-ready views            â”‚
â”‚                         â”‚  â€¢ kpi.sql - Latest price & change â”‚
â”‚                         â”‚  â€¢ candlestick.sql - OHLC charts   â”‚
â”‚                         â”‚  â€¢ treechart.sql - Volatility      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   VISUALIZATION LAYER                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“Š Power BI Dashboards (DirectQuery)                       â”‚
â”‚  â€¢ KPI Cards: Current price, % change, daily movement        â”‚
â”‚  â€¢ Candlestick Charts: 12-period OHLC with trend lines      â”‚
â”‚  â€¢ Treemap: Stock volatility & relative risk analysis       â”‚
â”‚  â€¢ Live refresh via Snowflake connection                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Technical Stack

### **Data Ingestion & Streaming**
- **âš¡ Apache Kafka** - Distributed event streaming platform
- **ğŸ˜ Zookeeper** - Kafka cluster coordination
- **ğŸ–¥ï¸ Kafdrop** - Web UI for Kafka monitoring
- **ğŸ Python Producer/Consumer** - Custom scripts for API â†’ Kafka â†’ MinIO

### **Storage & Orchestration**
- **ğŸ’¾ MinIO** - S3-compatible object storage (data lake)
- **ğŸ”„ Apache Airflow** - Workflow automation & scheduling
- **ğŸ˜ PostgreSQL** - Airflow metadata database

### **Data Warehouse & Transformation**
- **â„ï¸ Snowflake** - Cloud data warehouse with compute separation
- **ğŸ› ï¸ DBT (Data Build Tool)** - SQL-based data transformations
- **ğŸ“Š Medallion Architecture** - Bronze â†’ Silver â†’ Gold layers

### **Analytics & Visualization**
- **ğŸ’¼ Power BI** - Interactive dashboards with DirectQuery
- **ğŸ“ˆ Advanced Charts** - Candlestick, treemap, KPI cards

## ğŸ“Š Data Models (DBT)

### **Bronze Layer** - Raw Data Extraction
```sql
-- bronze_queries.sql
-- Parse JSON VARIANT to structured columns
SELECT
    v:c::float AS current_price,
    v:h::float AS day_high,
    v:l::float AS day_low,
    v:symbol::string AS symbol,
    v:t::timestamp AS market_timestamp
FROM bronze_stock_raw
```

### **Silver Layer** - Data Cleansing
```sql
-- curated_stocks.sql
-- Round decimals, filter nulls, standardize formats
SELECT
    symbol,
    current_price,
    ROUND(day_high, 2) AS day_high,
    ROUND(change_percent, 4) AS change_percent
FROM bronze_stock_raw
WHERE current_price IS NOT NULL
```

### **Gold Layer** - Business Views

**1. KPI Dashboard** (`kpi.sql`)
- Latest price, change amount, % change per stock
- Window function for most recent record per symbol

**2. Candlestick Chart** (`candlestick.sql`)
- OHLC (Open, High, Low, Close) data
- 12-period rolling window with trend lines
- Daily aggregation with FIRST_VALUE/LAST_VALUE

**3. Volatility Treemap** (`treechart.sql`)
- Standard deviation of prices (absolute & relative)
- Average price per stock
- Risk analysis metrics

## ğŸš€ Quick Start

### Prerequisites
- Docker & Docker Compose
- Python 3.8+
- Snowflake account
- Finnhub API key (free tier: 60 calls/min)
- Power BI Desktop (optional for dashboards)

### Setup

```bash
# 1. Clone repository
git clone https://github.com/yourusername/real-time-stock-data-pipeline.git
cd real-time-stock-data-pipeline

# 2. Install Python dependencies
pip install -r requirements.txt

# 3. Start infrastructure (Kafka, MinIO, Airflow)
cd infra/
docker-compose up -d

# 4. Initialize Airflow database
docker-compose exec airflow-scheduler airflow db init
docker-compose exec airflow-webserver airflow users create \
  --username admin \
  --firstname Admin \
  --lastname User \
  --role Admin \
  --email admin@example.com \
  --password admin123

# 5. Create Kafka topic
# Access Kafdrop UI at http://localhost:9000
# Create topic: stock-quotes (partitions: 1, replication: 1)

# 6. Start data ingestion
python infra/producer/producer.py  # Run in background
python infra/consumer/consumer.py  # Run in background

# 7. Configure Snowflake connection in Airflow DAG
# Edit: infra/Dag/minio_to_snowflake.py
# Add: SNOWFLAKE_USER, SNOWFLAKE_PASSWORD, SNOWFLAKE_ACCOUNT

# 8. Setup DBT for Snowflake
cd dbt_models/
dbt init
dbt run  # Execute all transformations

# 9. Connect Power BI
# Get Data â†’ Snowflake
# Server: your-account.snowflakecomputing.com
# Warehouse: Stock_Wh
# Database: STOCKS_DB
# Connection: DirectQuery
```

### Access Points

| Service | URL | Credentials |
|---------|-----|-------------|
| Kafdrop (Kafka UI) | http://localhost:9000 | None |
| MinIO Console | http://localhost:9001 | admin / password123 |
| Airflow Webserver | http://localhost:8080 | admin / admin123 |
| Snowflake | your-account.snowflakecomputing.com | Your credentials |

## ğŸ“ˆ Power BI Dashboard Features

### **KPI Cards**
- **Current Price** - Real-time stock value
- **Change Amount** - Absolute price movement ($)
- **Change Percent** - Relative daily change (%)

### **Candlestick Chart**
- **12-period OHLC** - Open, High, Low, Close
- **Trend Lines** - Moving average overlay
- **Time-series Analysis** - Daily market behavior

### **Volatility Treemap**
- **Stock Comparison** - Size by average price
- **Risk Metrics** - Color by volatility (STDDEV)
- **Relative Volatility** - Coefficient of variation

## ğŸ”§ Configuration Files

### **Docker Compose Services**
- `zookeeper` - Kafka coordination (port 2181)
- `kafka` - Event streaming (ports 9092, 29092)
- `kafdrop` - Kafka UI (port 9000)
- `minio` - Object storage (ports 9001, 9002)
- `airflow-webserver` - Airflow UI (port 8080)
- `airflow-scheduler` - Task scheduling
- `postgres` - Airflow metadata (port 5432)

### **DBT Project Structure**
```
dbt_models/
â”œâ”€â”€ bronze/
â”‚   â”œâ”€â”€ bronze_queries.sql      # JSON parsing
â”‚   â””â”€â”€ source.yml              # Source table config
â”œâ”€â”€ silver/
â”‚   â””â”€â”€ curated_stocks.sql      # Data cleansing
â””â”€â”€ gold/
    â”œâ”€â”€ kpi.sql                 # Latest stock metrics
    â”œâ”€â”€ candlestick.sql         # OHLC chart data
    â””â”€â”€ treechart.sql           # Volatility analysis
```

## ğŸ¯ Pipeline Workflow

1. **Data Ingestion** (Every 6 seconds)
   - Producer fetches quotes from Finnhub API
   - Publishes to Kafka topic `stock-quotes`
   - Consumer reads from Kafka â†’ writes to MinIO

2. **Data Loading** (Every 1 minute)
   - Airflow DAG triggers
   - Downloads new files from MinIO
   - Stages in Snowflake internal stage
   - COPY INTO bronze table

3. **Data Transformation** (On-demand/Scheduled)
   - DBT runs Bronze â†’ Silver â†’ Gold transformations
   - Creates curated views for Power BI
   - Maintains data quality & business logic

4. **Visualization** (Real-time)
   - Power BI DirectQuery refreshes automatically
   - Dashboards reflect latest Snowflake data
   - Users interact with live stock analytics

## ğŸŒŸ Advanced Features

### **Schema Evolution**
- JSON VARIANT type in Snowflake for flexible schemas
- DBT models adapt to new fields automatically
- Backward-compatible transformations

### **Data Quality**
- Null filtering in Silver layer
- Decimal rounding for consistency
- Deduplication using window functions

### **Performance Optimization**
- Partitioned MinIO storage by symbol & timestamp
- Snowflake clustering on symbol column
- DBT incremental models for large datasets

### **Monitoring & Observability**
- Kafdrop for Kafka topic health
- Airflow task logs & alerting
- Snowflake query history & performance

## ğŸ¯ Real-world Use Cases

- **ğŸ“Š Investment Analysis** - Real-time portfolio tracking
- **ğŸ¤– Algorithmic Trading** - Low-latency market data feeds
- **ğŸ“ˆ Market Research** - Historical trend analysis
- **ğŸ’¼ Financial Reporting** - Executive dashboards
- **ğŸ“ Educational Platform** - Learn data engineering with real data

## ğŸš€ Future Enhancements

- [ ] **ğŸ¤– ML Integration** - Price prediction models with Snowflake ML
- [ ] **ğŸ“± Mobile Alerts** - Real-time price movement notifications
- [ ] **ğŸŒ Multi-exchange Support** - Global stock markets (NYSE, NASDAQ, LSE)
- [ ] **ğŸ“Š Advanced Metrics** - RSI, MACD, Bollinger Bands
- [ ] **ğŸ”” Anomaly Detection** - Alert on unusual price movements
- [ ] **âš¡ Change Data Capture** - Incremental DBT models for efficiency
- [ ] **ğŸ”— API Layer** - REST API for consuming transformed data

## ğŸ¤ Contributing

Contributions welcome! Focus areas:
- **ğŸ“ˆ Additional Stock Metrics** - Technical indicators & financial ratios
- **ğŸ”§ Pipeline Optimization** - Performance tuning & cost reduction
- **ğŸ“Š Dashboard Enhancements** - New visualizations & KPIs
- **ğŸ§ª Testing** - DBT tests & data quality checks

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE) for details.

---

**Real-time financial analytics with modern data engineering** ğŸ“ˆâš¡
